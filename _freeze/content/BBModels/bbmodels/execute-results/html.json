{
  "hash": "1af38eba30fd37887832ef84c34619b2",
  "result": {
    "markdown": "---\ntitle: \"Supervised ML - Regression\"\ndate: \"2023-06-12\"\noutput: \n    html_document:\n        toc: TRUE\n        theme: flatly\n        highlight: tango\n        code_folding: hide\n        df_print: paged\n---\n\n\n\n\n# Challenge Summary\n\nThis is a two part challenge:\n\nPart 1: Recreate plot_features(). Take the explanation data and use the first case to create a plot similar to the output of plot_features().\n\nexplanation %>% \n  as.tibble()\n  \ncase_1 <- explanation %>%\n    filter(case == 1)\n\ncase_1 %>%\n    plot_features()\nYou will need at least the layers geom_col() and coord_flip().\n\nBonus Objectives:\n\nGet your custom plot_features() function to scale to multiple cases\nUse theme arguments to modify the look of the plot\nPart 2: Recreate plot_explanations():\n\nTake the full explanation data and recreate the second plot.\n\nYou will need at least the layers geom_tile() and facet_wrap().\n\n# Libraries\n\nLoad the following libraries. \n\n\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-1_74ce3fbcba2f343fa6048a16a3b3ccf7'}\n\n```{.r .cell-code}\n# install.packages(\"plotly\")\n\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(broom)\nlibrary(umap)\nlibrary(ggrepel) # Addon for ggplot, so that the labels do not overlap\nlibrary(h2o)\nlibrary(lime)\n\n# Modeling\nlibrary(parsnip)\n\n# Preprocessing & Sampling\nlibrary(recipes)\nlibrary(rsample)\n\n# Modeling Error Metrics\nlibrary(yardstick)\n\n# Plotting Decision Trees\nlibrary(rpart.plot)\n```\n:::\n\n\n\n# Data\n\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-2_e71f5ef21c2d5e879517b0619adb57ad'}\n\n```{.r .cell-code}\n# Data set\n\nproduct_tbl <- read_csv(\"product_backorders.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 19053 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\ndbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nglimpse(product_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 19,053\nColumns: 23\n$ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n$ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n$ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n$ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n$ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n$ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n$ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n$ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n$ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n$ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n$ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n$ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n$ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n$ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n$ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n$ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n$ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n$ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ went_on_backorder <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n```\n:::\n\n```{.r .cell-code}\nproduct_proc_tbl <- product_tbl %>%\n  mutate_if(is.character, as.factor)\n\nsplit_product_tbl <- initial_split(product_proc_tbl, prop = 0.8)\ntrain_tbl <- training(split_product_tbl)\ntest_tbl <- testing(split_product_tbl)\n```\n:::\n\n\n## Specify the response and predictor variables\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-3_470496020da0435d60ff54fdc02f9d43'}\n\n```{.r .cell-code}\nrecipe_product <- \n  recipe(went_on_backorder ~ ., data = train_tbl) %>%\n  step_zv(all_predictors()) %>%\n  update_role(sku, new_role = \"ID\") %>%\n  prep()\n\ntrain_bake <- bake(recipe_product, new_data = train_tbl)\ntest_bake <- bake(recipe_product, new_data = test_tbl)\n```\n:::\n\n## AutoML\n\n::: {.cell hash='bbmodels_cache/html/beginH2o_76eca01e80ca9cd8fa0abcea4393efd6'}\n\n```{.r .cell-code}\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    C:\\Users\\docla\\AppData\\Local\\Temp\\RtmpknkS5Q\\filebc851379b/h2o_docla_started_from_r.out\n    C:\\Users\\docla\\AppData\\Local\\Temp\\RtmpknkS5Q\\filebc861c75fe7/h2o_docla_started_from_r.err\n\n\nStarting H2O JVM and connecting:  Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         1 seconds 775 milliseconds \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.40.0.4 \n    H2O cluster version age:    1 month and 16 days \n    H2O cluster name:           H2O_started_from_R_docla_elk288 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   3.99 GB \n    H2O cluster total cores:    8 \n    H2O cluster allowed cores:  8 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.3.0 (2023-04-21 ucrt) \n```\n:::\n\n```{.r .cell-code}\nsplit_h2o <- h2o.splitFrame(as.h2o(train_bake), ratios = c(0.8), seed = 2597)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o <- as.h2o(test_bake)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), y)\n\nleader_h2o <- h2o.loadModel(\"../Models/StackedEnsemble_AllModels_1_AutoML_1_20230613_132849\")\n```\n:::\n\n\n# Challenge\n\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-4_da53b5c29c89b8a267043516a92339d0'}\n\n```{.r .cell-code}\npredictions_tbl <- leader_h2o %>% \n    h2o.predict(newdata = test_h2o) %>%\n    as.tibble() %>%\n    bind_cols(\n        test_tbl %>%\n            select(sku, went_on_backorder )\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n:::\n\n## Explainer\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-5_213b9844b0f553172283796d72cf6e44'}\n\n```{.r .cell-code}\nexplainer <- train_tbl %>%\n    select(-went_on_backorder) %>%\n    lime(\n        model           = leader_h2o,\n        bin_continuous  = TRUE,\n        n_bins          = 4,\n        quantile_bins   = TRUE\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: in_transit_qty does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: pieces_past_due does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: local_bo_qty does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n```{.r .cell-code}\nexplainer\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$model\nModel Details:\n==============\n\nH2OBinomialModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_1_AutoML_1_20230613_132849 \nModel Summary for Stacked Ensemble: \n                                    key            value\n1                     Stacking strategy cross_validation\n2  Number of base models (used / total)              4/6\n3      # GBM base models (used / total)              3/4\n4      # DRF base models (used / total)              1/1\n5      # GLM base models (used / total)              0/1\n6                 Metalearner algorithm              GLM\n7    Metalearner fold assignment scheme           Random\n8                    Metalearner nfolds                5\n9               Metalearner fold_column               NA\n10   Custom metalearner hyperparameters             None\n\n\nH2OBinomialMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.03015203\nRMSE:  0.1736434\nLogLoss:  0.1085087\nMean Per-Class Error:  0.0863238\nAUC:  0.9860569\nAUCPR:  0.9220199\nGini:  0.9721139\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         No  Yes    Error       Rate\nNo     8555  224 0.025515  =224/8779\nYes     177 1026 0.147132  =177/1203\nTotals 8732 1250 0.040172  =401/9982\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold       value idx\n1                       max f1  0.400437    0.836527 178\n2                       max f2  0.195475    0.872602 245\n3                 max f0point5  0.620875    0.871935 117\n4                 max accuracy  0.508510    0.960629 148\n5                max precision  0.994382    1.000000   0\n6                   max recall  0.024546    1.000000 345\n7              max specificity  0.994382    1.000000   0\n8             max absolute_mcc  0.400437    0.813831 178\n9   max min_per_class_accuracy  0.202840    0.937350 242\n10 max mean_per_class_accuracy  0.195475    0.940333 245\n11                     max tns  0.994382 8779.000000   0\n12                     max fns  0.994382 1202.000000   0\n13                     max fps  0.000372 8779.000000 399\n14                     max tps  0.024546 1203.000000 345\n15                     max tnr  0.994382    1.000000   0\n16                     max fnr  0.994382    0.999169   0\n17                     max fpr  0.000372    1.000000 399\n18                     max tpr  0.024546    1.000000 345\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.04851357\nRMSE:  0.220258\nLogLoss:  0.1625482\nMean Per-Class Error:  0.1263632\nAUC:  0.9572626\nAUCPR:  0.758559\nGini:  0.9145252\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         No Yes    Error       Rate\nNo     2500 136 0.051593  =136/2636\nYes      71 282 0.201133    =71/353\nTotals 2571 418 0.069254  =207/2989\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold       value idx\n1                       max f1  0.301733    0.731518 199\n2                       max f2  0.156097    0.800000 254\n3                 max f0point5  0.507966    0.735003 136\n4                 max accuracy  0.449943    0.935764 156\n5                max precision  0.976778    1.000000   0\n6                   max recall  0.011360    1.000000 368\n7              max specificity  0.976778    1.000000   0\n8             max absolute_mcc  0.301733    0.695345 199\n9   max min_per_class_accuracy  0.133528    0.899090 266\n10 max mean_per_class_accuracy  0.136709    0.900071 264\n11                     max tns  0.976778 2636.000000   0\n12                     max fns  0.976778  350.000000   0\n13                     max fps  0.000414 2636.000000 399\n14                     max tps  0.011360  353.000000 368\n15                     max tnr  0.976778    1.000000   0\n16                     max fnr  0.976778    0.991501   0\n17                     max fpr  0.000414    1.000000 399\n18                     max tpr  0.011360    1.000000 368\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05002334\nRMSE:  0.223659\nLogLoss:  0.1686964\nMean Per-Class Error:  0.153548\nAUC:  0.9525321\nAUCPR:  0.7552888\nGini:  0.9050642\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n          No  Yes    Error        Rate\nNo     10270  522 0.048369  =522/10792\nYes      378 1083 0.258727   =378/1461\nTotals 10648 1605 0.073451  =900/12253\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold        value idx\n1                       max f1  0.352431     0.706458 202\n2                       max f2  0.137066     0.779900 277\n3                 max f0point5  0.677497     0.736291 101\n4                 max accuracy  0.501552     0.933159 157\n5                max precision  0.979297     1.000000   0\n6                   max recall  0.000392     1.000000 399\n7              max specificity  0.979297     1.000000   0\n8             max absolute_mcc  0.444998     0.666214 173\n9   max min_per_class_accuracy  0.120204     0.888807 284\n10 max mean_per_class_accuracy  0.104979     0.889933 292\n11                     max tns  0.979297 10792.000000   0\n12                     max fns  0.979297  1458.000000   0\n13                     max fps  0.000392 10792.000000 399\n14                     max tps  0.000392  1461.000000 399\n15                     max tnr  0.979297     1.000000   0\n16                     max fnr  0.979297     0.997947   0\n17                     max fpr  0.000392     1.000000 399\n18                     max tpr  0.000392     1.000000 399\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n                mean        sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\naccuracy    0.928585  0.007752   0.922282   0.939715   0.927885   0.920700\nauc         0.952844  0.004395   0.946725   0.957085   0.955305   0.949760\nerr         0.071415  0.007752   0.077718   0.060285   0.072115   0.079301\nerr_count 175.000000 19.000000 188.000000 148.000000 180.000000 195.000000\nf0point5    0.697435  0.034539   0.681052   0.739164   0.688790   0.653393\n          cv_5_valid\naccuracy    0.932343\nauc         0.955344\nerr         0.067657\nerr_count 164.000000\nf0point5    0.724777\n\n---\n                        mean        sd cv_1_valid cv_2_valid cv_3_valid\nprecision           0.687130  0.049907   0.680135   0.751969   0.662198\nr2                  0.524032  0.026224   0.481173   0.535484   0.547705\nrecall              0.752175  0.064045   0.684746   0.692029   0.820598\nresidual_deviance 824.421200 42.222744 887.693100 769.068800 816.439100\nrmse                0.223489  0.007711   0.235702   0.215294   0.219011\nspecificity         0.952420  0.014013   0.955273   0.971088   0.942597\n                  cv_4_valid cv_5_valid\nprecision           0.622995   0.718354\nr2                  0.518086   0.537709\nrecall              0.811847   0.751656\nresidual_deviance 824.678160 824.226900\nrmse                0.222893   0.224544\nspecificity         0.935083   0.958058\n\n$preprocess\nfunction (x) \nx\n<bytecode: 0x000002dcd9ff8428>\n<environment: 0x000002dcd9fe8df0>\n\n$bin_continuous\n[1] TRUE\n\n$n_bins\n[1] 4\n\n$quantile_bins\n[1] TRUE\n\n$use_density\n[1] TRUE\n\n$feature_type\n              sku      national_inv         lead_time    in_transit_qty \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n forecast_3_month  forecast_6_month  forecast_9_month     sales_1_month \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n    sales_3_month     sales_6_month     sales_9_month          min_bank \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n  potential_issue   pieces_past_due  perf_6_month_avg perf_12_month_avg \n         \"factor\"         \"numeric\"         \"numeric\"         \"numeric\" \n     local_bo_qty         deck_risk     oe_constraint         ppap_risk \n        \"numeric\"          \"factor\"          \"factor\"          \"factor\" \n    stop_auto_buy          rev_stop \n         \"factor\"          \"factor\" \n\n$bin_cuts\n$bin_cuts$sku\n     0%     25%     50%     75%    100% \n1112390 1509893 1925344 2827490 3284775 \n\n$bin_cuts$national_inv\n    0%    25%    50%    75%   100% \n -1193      3     11     63 730722 \n\n$bin_cuts$lead_time\n  0%  25%  50% 100% \n   0    4    8   52 \n\n$bin_cuts$in_transit_qty\n[1]      0  42730  85460 128190 170920\n\n$bin_cuts$forecast_3_month\n    0%    75%   100% \n     0      9 479808 \n\n$bin_cuts$forecast_6_month\n    0%    75%   100% \n     0     20 967776 \n\n$bin_cuts$forecast_9_month\n     0%     75%    100% \n      0      30 1418208 \n\n$bin_cuts$sales_1_month\n    0%    75%   100% \n     0      5 186451 \n\n$bin_cuts$sales_3_month\n    0%    50%    75%   100% \n     0      1     16 550609 \n\n$bin_cuts$sales_6_month\n     0%     50%     75%    100% \n      0       3      32 1136154 \n\n$bin_cuts$sales_9_month\n     0%     50%     75%    100% \n      0       5      47 1759152 \n\n$bin_cuts$min_bank\n   0%   75%  100% \n    0     3 85584 \n\n$bin_cuts$potential_issue\nNULL\n\n$bin_cuts$pieces_past_due\n[1]     0  3456  6912 10368 13824\n\n$bin_cuts$perf_6_month_avg\n    0%    25%    50%    75%   100% \n-99.00   0.63   0.82   0.96   1.00 \n\n$bin_cuts$perf_12_month_avg\n    0%    25%    50%    75%   100% \n-99.00   0.66   0.80   0.95   1.00 \n\n$bin_cuts$local_bo_qty\n[1]    0.00  316.75  633.50  950.25 1267.00\n\n$bin_cuts$deck_risk\nNULL\n\n$bin_cuts$oe_constraint\nNULL\n\n$bin_cuts$ppap_risk\nNULL\n\n$bin_cuts$stop_auto_buy\nNULL\n\n$bin_cuts$rev_stop\nNULL\n\n\n$feature_distribution\n$feature_distribution$sku\n\n        1         2         3         4 \n0.2500328 0.2499672 0.2499672 0.2500328 \n\n$feature_distribution$national_inv\n\n        1         2         3         4 \n0.2740454 0.2260202 0.2516074 0.2483270 \n\n$feature_distribution$lead_time\n\n        1         2         3 \n0.2979924 0.4132004 0.2321874 \n\n$feature_distribution$in_transit_qty\n\n           1            2            4 \n9.998688e-01 6.560819e-05 6.560819e-05 \n\n$feature_distribution$forecast_3_month\n\n        1         2 \n0.7539037 0.2460963 \n\n$feature_distribution$forecast_6_month\n\n        1         2 \n0.7552815 0.2447185 \n\n$feature_distribution$forecast_9_month\n\n        1         2 \n0.7552159 0.2447841 \n\n$feature_distribution$sales_1_month\n\n        1         2 \n0.7609894 0.2390106 \n\n$feature_distribution$sales_3_month\n\n        1         2         3 \n0.5015090 0.2506889 0.2478021 \n\n$feature_distribution$sales_6_month\n\n        1         2         3 \n0.5100381 0.2418318 0.2481302 \n\n$feature_distribution$sales_9_month\n\n        1         2         3 \n0.5148931 0.2360583 0.2490487 \n\n$feature_distribution$min_bank\n\n        1         2 \n0.7558719 0.2441281 \n\n$feature_distribution$potential_issue\n\n         No         Yes \n0.998622228 0.001377772 \n\n$feature_distribution$pieces_past_due\n\n           1            2            4 \n9.998688e-01 6.560819e-05 6.560819e-05 \n\n$feature_distribution$perf_6_month_avg\n\n        1         2         3         4 \n0.2608582 0.2558719 0.2348117 0.2484582 \n\n$feature_distribution$perf_12_month_avg\n\n        1         2         3         4 \n0.2815247 0.2246424 0.2610550 0.2327779 \n\n$feature_distribution$local_bo_qty\n\n           1            2            4 \n0.9994751345 0.0003280409 0.0001968246 \n\n$feature_distribution$deck_risk\n\n       No       Yes \n0.7790972 0.2209028 \n\n$feature_distribution$oe_constraint\n\n          No          Yes \n0.9997375672 0.0002624328 \n\n$feature_distribution$ppap_risk\n\n       No       Yes \n0.8797402 0.1202598 \n\n$feature_distribution$stop_auto_buy\n\n        No        Yes \n0.03424747 0.96575253 \n\n$feature_distribution$rev_stop\n\n          No          Yes \n0.9995407427 0.0004592573 \n\n\nattr(,\"class\")\n[1] \"data_frame_explainer\" \"explainer\"            \"list\"                \n```\n:::\n:::\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-6_1fb93103316ea8ef274227185b8edcd1'}\n\n```{.r .cell-code}\nexplanation <- test_tbl %>%\n    slice(1) %>%\n    select(-went_on_backorder) %>%\n    lime::explain(\n    \n        # Pass our explainer object\n        explainer = explainer,\n        # Because it is a binary classification model: 1\n        n_labels   = 1,\n        # number of features to be returned\n        n_features = 8,\n        # number of localized linear models\n        n_permutations = 5000,\n        # Let's start with 1\n        kernel_width   = 1\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nexplanation\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 13\n  model_type    case  label label_prob model_r2 model_intercept model_prediction\n  <chr>         <chr> <chr>      <dbl>    <dbl>           <dbl>            <dbl>\n1 classificati… 1     Yes        0.901    0.396          0.0796            0.671\n2 classificati… 1     Yes        0.901    0.396          0.0796            0.671\n3 classificati… 1     Yes        0.901    0.396          0.0796            0.671\n4 classificati… 1     Yes        0.901    0.396          0.0796            0.671\n5 classificati… 1     Yes        0.901    0.396          0.0796            0.671\n6 classificati… 1     Yes        0.901    0.396          0.0796            0.671\n7 classificati… 1     Yes        0.901    0.396          0.0796            0.671\n8 classificati… 1     Yes        0.901    0.396          0.0796            0.671\n# ℹ 6 more variables: feature <chr>, feature_value <dbl>, feature_weight <dbl>,\n#   feature_desc <chr>, data <list>, prediction <list>\n```\n:::\n:::\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-7_b05e277e05b719cb6a3993a2886cdfbd'}\n\n```{.r .cell-code}\nexplanation %>%\n    as.tibble() %>%\n    select(feature:prediction) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 6\n  feature    feature_value feature_weight feature_desc data         prediction  \n  <chr>              <dbl>          <dbl> <chr>        <list>       <list>      \n1 in_transi…             0         0.221  in_transit_… <named list> <named list>\n2 national_…             0         0.227  national_in… <named list> <named list>\n3 sku              1114823         0.118  sku <= 1509… <named list> <named list>\n4 potential…             1        -0.0895 potential_i… <named list> <named list>\n5 min_bank               2        -0.0883 min_bank <=… <named list> <named list>\n6 local_bo_…             0         0.0901 local_bo_qt… <named list> <named list>\n7 forecast_…            31         0.0575 20 < foreca… <named list> <named list>\n8 sales_1_m…             7         0.0547 5 < sales_1… <named list> <named list>\n```\n:::\n:::\n\n\n## plot_features\n\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-8_bc15b73b2c85866b3972924c6d227186'}\n\n```{.r .cell-code}\nplot_features <- function(explanation) {\n  ggplot(explanation) +\n  geom_col(aes(feature_desc %>% \n                 str_replace_all(pattern = \"_\", replacement = \" \") %>% \n                 str_to_title(),\n               feature_weight,\n               fill = factor(sign(feature_weight)))) +\n  coord_flip() +\n  scale_fill_discrete(name = \"Influence\", labels = c(\"Contradicts\", \"Supports\")) +\n  theme(legend.position=\"bottom\") +\n  labs(\n    title = \"Weighting of features\",\n    subtitle = paste(\"Probability:\",\n                     as.character(round(unique(explanation$label_prob),4)),\n                     \"\\nExplanation Fit:\",\n                     as.character(round(unique(explanation$model_r2),4)) ),\n    x = \"Weight\",\n    y = \"Feature\",\n  )\n}\n```\n:::\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-9_1b19b5802dd2d63772ad56ae38a6d5e9'}\n\n```{.r .cell-code}\nplot_features(explanation)\n```\n\n::: {.cell-output-display}\n![](bbmodels_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## plot_explanations\n\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-10_4cdc2d845200f0359b9a8852ba63b63d'}\n\n```{.r .cell-code}\nexplanation <- test_tbl %>%\n    slice(1:20) %>%\n    select(-went_on_backorder) %>%\n    lime::explain(\n        explainer = explainer,\n        n_labels   = 1,\n        n_features = 8,\n        n_permutations = 5000,\n        kernel_width   = 0.5\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n:::\n\n::: {.cell hash='bbmodels_cache/html/unnamed-chunk-11_02141870dc477ccc0108a08cf51f6b6b'}\n\n```{.r .cell-code}\nplot_explanations <- function(explanation, slicesize = 20) {\n  ggplot(explanation) +\n  geom_tile(aes(factor(case, levels = 1:slicesize),\n                feature_desc %>% \n                 str_replace_all(pattern = \"_\", replacement = \" \") %>% \n                 str_to_title(),\n                fill = feature_weight)) +\n  facet_wrap(~ label) +\n  scale_fill_continuous(name = \"Feature\\nWeight\") +\n  labs(\n    x = \"Case\",\n    y = \"Feature\"\n  )\n}\nplot_explanations(explanation, 20)\n```\n\n::: {.cell-output-display}\n![](bbmodels_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\nCongratulations! You are done with the 6th challenge!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}